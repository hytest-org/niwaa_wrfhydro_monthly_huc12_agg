2025-03-13 09:54:16,893 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.26.1.73:38905'
2025-03-13 09:54:18,427 - distributed.worker - INFO -       Start worker at:    tcp://172.26.1.73:40971
2025-03-13 09:54:18,428 - distributed.worker - INFO -          Listening to:    tcp://172.26.1.73:40971
2025-03-13 09:54:18,428 - distributed.worker - INFO -           Worker name:             SLURMCluster-1
2025-03-13 09:54:18,428 - distributed.worker - INFO -          dashboard at:          172.26.1.73:45911
2025-03-13 09:54:18,428 - distributed.worker - INFO - Waiting to connect to:    tcp://172.26.1.35:46563
2025-03-13 09:54:18,428 - distributed.worker - INFO - -------------------------------------------------
2025-03-13 09:54:18,428 - distributed.worker - INFO -               Threads:                          1
2025-03-13 09:54:18,428 - distributed.worker - INFO -                Memory:                   9.31 GiB
2025-03-13 09:54:18,428 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space-84860/worker-o68i16xi
2025-03-13 09:54:18,428 - distributed.worker - INFO - -------------------------------------------------
2025-03-13 09:54:19,122 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-13 09:54:19,122 - distributed.worker - INFO -         Registered to:    tcp://172.26.1.35:46563
2025-03-13 09:54:19,123 - distributed.worker - INFO - -------------------------------------------------
2025-03-13 09:54:19,123 - distributed.core - INFO - Starting established connection to tcp://172.26.1.35:46563
2025-03-13 10:04:53,524 - distributed.worker - INFO - Stopping worker at tcp://172.26.1.73:40971. Reason: scheduler-close
slurmstepd: error: *** JOB 8024856 ON cn061 CANCELLED AT 2025-03-13T10:04:53 ***
2025-03-13 10:04:53,543 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://172.26.1.73:54768 remote=tcp://172.26.1.35:46563>
Traceback (most recent call last):
  File "/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/tornado/gen.py", line 766, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://172.26.1.73:54768 remote=tcp://172.26.1.35:46563>: Stream is closed
2025-03-13 10:04:53,549 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://172.26.1.73:38905'. Reason: scheduler-close
2025-03-13 10:04:53,595 - distributed.core - INFO - Received 'close-stream' from tcp://172.26.1.35:46563; closing.
2025-03-13 10:04:53,595 - distributed.nanny - INFO - Worker closed

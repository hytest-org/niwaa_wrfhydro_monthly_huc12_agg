{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49a34541-69af-4144-bf0b-13ad230fdd95",
   "metadata": {},
   "source": [
    "## CONUS Water Budget Components from WRF-Hydro\n",
    "\n",
    "#### Notes on CONUS Water Budget Processing\n",
    "\n",
    "Aubrey has already processed the data from 3-hourly to monthly summaries on the native WRF-Hydro/NWM grids. We will use this temporally-aggregated output to begin the spatial aggregation for the sake of reduced processing time.\n",
    "\n",
    "| Output File Type      | Description | Path on Glade |\n",
    "| ----------- | ----------- | ----------- |\n",
    "| **LDASOUT** | WRF-Hydro 1km output files | `/glade/campaign/ncar/USGS_Water/adugger/IWAA/retro_42yr/monthly_files/water_*.nc` |\n",
    "| **CHRTOUT** | WRF-Hydro/NWM Network files | `/glade/campaign/ncar/USGS_Water/adugger/IWAA/retro_42yr/monthly_files/chrt_*.nc` |\n",
    "| **LDASIN** | Noah-MP LSM Input files | `/glade/campaign/ncar/USGS_Water/adugger/IWAA/retro_42yr/monthly_files/clim_*.nc` |\n",
    "| **GWOUT** | WRF-Hydro/NWM Groundwater basins | `/glade/campaign/ncar/USGS_Water/adugger/IWAA/retro_42yr/monthly_files/gw_*.nc` |\n",
    "\n",
    "For water budget components and how they map to the above files, refer to the spreadsheet here: https://docs.google.com/spreadsheets/d/1m486t3jXBcrvST3AtlVktyeCnjJqZgn1Gd4X70Bso10/edit#gid=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a93c51-fa58-40b7-9d61-fb6441cae082",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "This notebook is intended to process the zonal (spatial) statistics between NWM Retrospective outputs and a set of gridded 'zones', which can be any spatial unit such as counties, states, HUCs, etc. Those inputs must already be resolved on the intended NWM grid (LSM - 1km, or routing - 250m) and optionally subset to any spatial subset of the NWM retrospective data (i.e. the grids must match exactly). This script assumes all 'zone' datasets are written in typical GIS fashion from north to south. If an LSM grid is requested, the zone dataset will be flipped south-to-north in this script. \n",
    "\n",
    "A 2D groupby operation is performed using the `flox` python package, though this functionality has been incorporated into certain branches of the `xarray` library and may become available soon in the main branch.\n",
    "\n",
    "https://github.com/dask/dask/issues/5085#issuecomment-513043034\n",
    "\n",
    "## Processing Environment\n",
    "\n",
    "The Python environment used is a conda environment `analysis`, here:\n",
    "\n",
    "* /glade/work/ksampson/conda-envs/analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece6e02f-d8cc-44ba-8a9b-7f83a2028073",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72da8374-ac14-451b-8847-d1fb4a353df6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process initiated at Thu Feb 27 12:31:11 2025\n"
     ]
    }
   ],
   "source": [
    "# --- Import Modules --- #\n",
    "\n",
    "# Import Python Core Modules\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import tracemalloc\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Some environment variables important to dask\n",
    "os.environ[\"MALLOC_TRIM_THRESHOLD_\"] = \"0\"\n",
    "os.environ[\"DASK_DISTRIBUTED__SCHEDULER__ACTIVE_MEMORY_MANAGER__START\"] = \"True\"\n",
    "os.environ[\"DASK_DISTRIBUTED__SCHEDULER__WORKER_SATURATION\"] = \"1.2\"\n",
    "if 'DASK_ROOT_CONFIG' in os.environ:\n",
    "    del os.environ['DASK_ROOT_CONFIG']    # This seems pretty important\n",
    "import dask\n",
    "from dask.distributed import Client, progress, LocalCluster, performance_report\n",
    "#from dask_jobqueue import PBSCluster\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.diagnostics import ProgressBar\n",
    "import dask.array as da\n",
    "  \n",
    "\n",
    "# Import Additional Modules\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import zarr\n",
    "import flox.xarray\n",
    "\n",
    "# Import functions from local repository\n",
    "#sys.path.append(r'/glade/scratch/ksampson/Water_Budget/usgs_water/daily_retro')\n",
    "sys.path.append(r'/caldera/hovenweep/projects/usgs/water/impd/hytest/working/niwaa_wrfhydro_monthly_huc12_aggregations/niwaa_wrfhydro_monthly_huc12_agg/Working')\n",
    "from usgs_common import *\n",
    "\n",
    "tic = time.time()\n",
    "print('Process initiated at {0}'.format(time.ctime()))\n",
    "# --- End Import Modules --- #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc91b816-8070-446b-aad2-ba42490e76a6",
   "metadata": {},
   "source": [
    "## Define the input files and other relevant local variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "501fc30e-4e9e-4df4-b35c-12914ffce388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NWM output type ['LDASOUT', 'RTOUT', 'Precip']\n",
    "NWM_type = 'LDASOUT'\n",
    "\n",
    "# Variable to process - list form, from LDASOUT, and LDASIN\n",
    "variables = ['deltaACCET',\n",
    "             'deltaACSNOW',\n",
    "             'deltaSNEQV',\n",
    "             'deltaSOILM',\n",
    "             'deltaUGDRNOFF',\n",
    "             'deltaSOILM_depthmean',\n",
    "             'avgSNEQV',\n",
    "             'avgSOILM',\n",
    "             'avgSOILM_depthmean',\n",
    "             'avgSOILM_wltadj_depthmean',\n",
    "             'avgSOILSAT',\n",
    "             'avgSOILSAT_wltadj_top1',\n",
    "             'totPRECIP',\n",
    "             'avgT2D']\n",
    "\n",
    "# Give a name to the zone dataset, which will be the name of the zone variable\n",
    "zone_name = 'WBDHU12'\n",
    "\n",
    "# Perform temporal subset on inputs?\n",
    "temporal_subset = False\n",
    "\n",
    "# Choose the temporal range, if temporal_subset is true\n",
    "#time_subset_bounds = slice('2009-10-01', '2019-09-30')    # First IWAAS batch\n",
    "#time_subset_bounds = slice('2019-10-01', '2021-09-30')     # Second IWAAS batch\n",
    "#time_subset_bounds = slice('2009-10-01', '2021-09-30')     # Second IWAAS batch\n",
    "\n",
    "time_subset_bounds = slice('2012-10-01', '2013-09-30')     # Test Hytest batch (2 years)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4516e30-d401-4707-ad8d-3867a7e48958",
   "metadata": {},
   "source": [
    "## Define the output files and other relevant variables to outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61db1af7-6028-4664-a43a-3d604df96b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory\n",
    "#outDir = r'/glade/scratch/ksampson/USGS/CONUS_Water_Budget/Water_Budget'\n",
    "outDir = r'/caldera/hovenweep/projects/usgs/water/impd/hytest/working/niwaa_wrfhydro_monthly_huc12_aggregations/agg_out'\n",
    "# Basename for output files - extension will be applied later\n",
    "#output_pattern = 'CONUS_HUC12_WB_2D_19791001_20001231_notFinal'\n",
    "output_pattern = 'CONUS_HUC12_WB_2D_19791001_20220930'\n",
    "\n",
    "# Other variables to help with the file output naming convention\n",
    "write_CSV = True\n",
    "write_NC = True\n",
    "\n",
    "# Apply a landmask to the weight grid so that water cells are not considered in the spatial statistics? \n",
    "# Only applies to LSM grid variables\n",
    "landmask_results = True\n",
    "\n",
    "# Variables that will be normalized to the full land area (not landmasked land area)\n",
    "non_landmask_vars = ['Precip', 'landmask']\n",
    "\n",
    "# Add variables that we want to process spatial stats for\n",
    "addVars = ['total_gridded_area'] + non_landmask_vars    # For all other processing\n",
    "#addVars = ['total_gridded_area']                        # For the soil moisture top layer variables\n",
    "\n",
    "# Calculate percent soil saturation as a derived output variable\n",
    "pct_sat = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c0a549-1354-43f5-a3d8-7a2951c49179",
   "metadata": {},
   "source": [
    "### Handle the processing of input variables if the source is raw NWM\n",
    "\n",
    "Use the NWM_type to define the input Zarr store, and any other processing requirements (unit conversion, time resampling, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd761ab6-fcab-4af2-847b-f3f5fe677ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36 files using wildcard \"water_*.nc\" (recursive=False) in the input directory:\n",
      "\t /caldera/hovenweep/projects/usgs/water/impd/hytest/working/niwaa_wrfhydro_monthly_huc12_aggregations/subset_LDASOUT_mo\n",
      "Found 33 files using wildcard \"clim_*.nc\" (recursive=False) in the input directory:\n",
      "\t /caldera/hovenweep/projects/usgs/water/impd/hytest/working/niwaa_wrfhydro_monthly_huc12_aggregations/subset_LDASIN_mo\n"
     ]
    }
   ],
   "source": [
    "# We will construct a list of files. They must all contain the same time and other dimensions in order to be concatenated using open_mfdataset\n",
    "convert_to_mm = False\n",
    "\n",
    "# Specify the directory where the precip (LDASIN, clim_*.nc) files are stored. This can be different in some cases than the othe files\n",
    "#clim_dir = r'/glade/p/ral/hap/adugger/projects/USGS_HyTEST/WaterBudget/datasets/IWAA_WH/monthly_files/wrfhydro_10yr'\n",
    "#clim_dir = r'/glade/scratch/adugger/USGS_HyTEST/IWAA/monthly_files_42yr/final_outputs'\n",
    "#clim_dir = r'/glade/campaign/ncar/USGS_Water/adugger/IWAA/retro_42yr/monthly_files'\n",
    "\n",
    "clim_dir = r'/caldera/hovenweep/projects/usgs/water/impd/hytest/working/niwaa_wrfhydro_monthly_huc12_aggregations/subset_LDASIN_mo'\n",
    "\n",
    "# Specify the directory where the LDASOUT (water_*.nc) files are stored.\n",
    "#land_dir = r'/glade/p/ral/hap/adugger/projects/USGS_HyTEST/WaterBudget/datasets/IWAA_WH/monthly_files/wrfhydro_10yr'\n",
    "#land_dir = r'/glade/scratch/adugger/USGS_HyTEST/IWAA/monthly_files_42yr/final_outputs'\n",
    "#land_dir = r'/glade/campaign/ncar/USGS_Water/adugger/IWAA/retro_42yr/monthly_files'\n",
    "\n",
    "land_dir = r'/caldera/hovenweep/projects/usgs/water/impd/hytest/working/niwaa_wrfhydro_monthly_huc12_aggregations/subset_LDASOUT_mo'\n",
    "\n",
    "# Add a second set of variables from a different set of files\n",
    "file_in = get_files_wildcard(land_dir, \n",
    "                             file_pattern='water_*.nc', \n",
    "                             recursive=False)\n",
    "\n",
    "# Obtain list of files from wildcard\n",
    "file_in2 = get_files_wildcard(clim_dir, \n",
    "                             file_pattern='clim_*.nc', \n",
    "                             recursive=False)\n",
    "\n",
    "# If no additional datasets are needed\n",
    "#file_in2 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1a0a1b-06ad-4f1d-9259-a858c2c62ae0",
   "metadata": {},
   "source": [
    "### Spin up a Dask Cluster\n",
    "https://ncar.github.io/esds/posts/2021/casper_pbs_dask/index.html\n",
    "\n",
    "Currently, the best way to execute this notebook is on a Casper PBS login node, though it may also be run on a Casper batch node with sufficient memory such that the individual workers do not incur >80% memory utilization. The current upper limit on the batch nodes is 36 cores per node and 1494Gb per node. Thus, for some datasets, such as routing grid resolution and high temporal frequncies, the script may overload the workers and stop responding.\n",
    "\n",
    "Suggested parameters for a Casper batch node are:\n",
    "\n",
    "Casper share nodes\n",
    "- 500-1494Gb per node (109 is Cheyenne batch node limit)\n",
    "- 2-36 cores\n",
    "- 1-24 hour wallclock time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96f98b20-b622-49fe-b8e6-13cd6074ca7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'cluster' object can be used to adjust cluster behavior.  i.e. 'cluster.adapt(minimum=10)'\n",
      "The 'client' object can be used to directly interact with the cluster.  i.e. 'client.submit(func)' \n",
      "The link to view the client dashboard is:\n",
      ">  http://172.26.1.92:8787/status\n",
      "CPU times: user 44.3 ms, sys: 4.49 ms, total: 48.8 ms\n",
      "Wall time: 82.2 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "try:\n",
    "    project='impd'\n",
    "    #project = os.environ['SLURM_JOB_ACCOUNT']\n",
    "except KeyError:\n",
    "    logging.error(\"SLURM_JOB_ACCOUNT is not set in the active environment. Are you on the login node? You should not be running this there.\")\n",
    "    raise\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "    processes=1, \n",
    "    cores=1, \n",
    "    memory='10GB', \n",
    "    #interface='ib0',\n",
    "    account=project, \n",
    "    walltime='01:00:00',      \n",
    "    #job_extra={'hint': 'multithread'},\n",
    "    shared_temp_directory='/home/lstaub',\n",
    "    #scheduler_options = {'dashboard_address': ':32939'}\n",
    ")\n",
    "cluster.adapt(minimum=2, maximum=30)\n",
    "\n",
    "client = Client(cluster)\n",
    "\n",
    "    \n",
    "print(\"The 'cluster' object can be used to adjust cluster behavior.  i.e. 'cluster.adapt(minimum=10)'\")\n",
    "print(\"The 'client' object can be used to directly interact with the cluster.  i.e. 'client.submit(func)' \")\n",
    "print(f\"The link to view the client dashboard is:\\n>  {client.dashboard_link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f44f12f-8c2d-461e-b424-ca8dbc98d7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 12:50:44,766 - distributed.deploy.adaptive_core - INFO - Adaptive stop\n"
     ]
    }
   ],
   "source": [
    "client.shutdown()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81bc6d6-6beb-4681-8124-246a191baa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "##NCARS version\n",
    "\n",
    "%%time\n",
    "\n",
    "# Change your url to the dask dashboard so you can see it\n",
    "dask.config.config.get('distributed').get('dashboard').update({'link':'{JUPYTERHUB_SERVICE_PREFIX}/proxy/{port}/status'})\n",
    "\n",
    "# # If you are already on a cluster, use the local cluster, aliased with Client\n",
    "# client = Client()\n",
    "# client\n",
    "\n",
    "#project_key = 'NHAP0007'    # IWAA, Cheyenne only\n",
    "project_key = 'P48500028'\n",
    "\n",
    "# To spin up a PBS cluster (Cheyenne, Casper, etc.), use the syntax below\n",
    "cluster = PBSCluster(\n",
    "    cores=1, \n",
    "    queue='casper', \n",
    "    project=project_key, \n",
    "    memory='10GiB', \n",
    "    walltime='02:00:00',  \n",
    "    death_timeout=75,\n",
    "    resource_spec = 'select=1:ncpus=1:mem=10GB',\n",
    "    local_directory=os.path.join(outDir, \"dask\"),\n",
    "    job_script_prologue=[\"export DASK_DISTRIBUTED__SCHEDULER__WORKER_SATURATION=1.2\"],)\n",
    "    # interface='ib0',)\n",
    "    \n",
    "print(cluster.job_script())\n",
    "\n",
    "# For a set number of cores\n",
    "# n_jobs = 10\n",
    "# n_jobs_start = n_jobs\n",
    "# cluster.scale(jobs=n_jobs)\n",
    "# client = Client(cluster)\n",
    "# client.wait_for_workers(n_jobs_start)\n",
    "\n",
    "# For an adaptable number of cores\n",
    "cluster.adapt(minimum=10, maximum=100)\n",
    "\n",
    "# Start the client\n",
    "client = Client(cluster)\n",
    "\n",
    "# Display the client\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04508e81-8d01-432c-b266-4effd98cab65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 12:51:49,926 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.63 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:49,926 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.63 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,283 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.67 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,284 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.67 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,289 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.22 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,289 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.22 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,306 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.93 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,562 - distributed.worker.memory - WARNING - Worker is at 87% memory usage. Pausing worker.  Process memory: 140.30 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,562 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.30 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,567 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.90 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,568 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.90 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,667 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.36 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,689 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.89 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,690 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.89 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,731 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.68 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,732 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.68 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,750 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.64 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,750 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.64 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,793 - distributed.worker.memory - WARNING - Worker is at 91% memory usage. Pausing worker.  Process memory: 145.74 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,794 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 145.74 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,923 - distributed.worker.memory - WARNING - Worker is at 89% memory usage. Pausing worker.  Process memory: 142.78 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,923 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.78 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,925 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.39 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,926 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.39 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:50,962 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.93 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,000 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.36 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,019 - distributed.worker.memory - WARNING - Worker is at 90% memory usage. Pausing worker.  Process memory: 145.57 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,020 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 145.57 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,039 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.20 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,039 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.20 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,062 - distributed.worker.memory - WARNING - Worker is at 90% memory usage. Pausing worker.  Process memory: 144.02 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,063 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 144.02 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,081 - distributed.worker.memory - WARNING - Worker is at 87% memory usage. Pausing worker.  Process memory: 140.31 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,081 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.31 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,100 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.06 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,101 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.06 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,146 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.68 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,147 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.68 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,156 - distributed.worker.memory - WARNING - Worker is at 89% memory usage. Pausing worker.  Process memory: 142.42 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,156 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.42 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,192 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.61 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,192 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.61 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,387 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.31 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,388 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.31 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,425 - distributed.worker.memory - WARNING - Worker is at 91% memory usage. Pausing worker.  Process memory: 146.54 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,427 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 146.54 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,648 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 142.23 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,649 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.23 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,670 - distributed.worker.memory - WARNING - Worker is at 89% memory usage. Pausing worker.  Process memory: 143.49 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,670 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 143.49 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,683 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.64 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,684 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.64 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,701 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.29 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,702 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.29 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,729 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 142.03 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,729 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.03 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,738 - distributed.worker.memory - WARNING - Worker is at 87% memory usage. Pausing worker.  Process memory: 139.46 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,738 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 139.46 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,745 - distributed.worker.memory - WARNING - Worker is at 90% memory usage. Pausing worker.  Process memory: 144.04 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,746 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 144.04 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,910 - distributed.worker.memory - WARNING - Worker is at 89% memory usage. Pausing worker.  Process memory: 142.66 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,911 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.66 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:51,962 - distributed.worker.memory - WARNING - Worker is at 91% memory usage. Pausing worker.  Process memory: 145.86 MiB -- Worker memory limit: 160.00 MiB\n",
      "te a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 145.86 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,059 - distributed.worker.memory - WARNING - Worker is at 91% memory usage. Pausing worker.  Process memory: 145.80 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,060 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 145.80 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,078 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.25 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,079 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.25 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,115 - distributed.worker.memory - WARNING - Worker is at 87% memory usage. Pausing worker.  Process memory: 140.73 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,116 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.73 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,161 - distributed.worker.memory - WARNING - Worker is at 87% memory usage. Pausing worker.  Process memory: 140.47 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,162 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.47 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,195 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.79 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,195 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.79 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,224 - distributed.worker.memory - WARNING - Worker is at 87% memory usage. Pausing worker.  Process memory: 139.78 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,224 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 139.78 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,242 - distributed.worker.memory - WARNING - Worker is at 89% memory usage. Pausing worker.  Process memory: 143.48 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,242 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 143.48 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,261 - distributed.worker.memory - WARNING - Worker is at 89% memory usage. Pausing worker.  Process memory: 143.56 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,262 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 143.56 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,286 - distributed.worker.memory - WARNING - Worker is at 87% memory usage. Pausing worker.  Process memory: 139.82 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,287 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 139.82 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,314 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.30 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,314 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.30 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,353 - distributed.worker.memory - WARNING - Worker is at 87% memory usage. Pausing worker.  Process memory: 139.89 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,353 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 139.89 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,371 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.21 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,371 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.21 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,386 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 142.34 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,387 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.34 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,547 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Pausing worker.  Process memory: 139.18 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,548 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 139.18 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,901 - distributed.worker.memory - WARNING - Worker is at 87% memory usage. Pausing worker.  Process memory: 139.77 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:52,901 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 139.77 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:53,303 - distributed.worker.memory - WARNING - Worker is at 87% memory usage. Pausing worker.  Process memory: 140.80 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:53,303 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.80 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:54,093 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.72 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:54,094 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.72 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:56,205 - distributed.worker.memory - WARNING - Worker is at 89% memory usage. Pausing worker.  Process memory: 142.70 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:56,206 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.70 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:56,554 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 142.08 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:56,555 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.08 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:57,100 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.47 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:57,100 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.47 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:57,118 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.88 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:57,118 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.88 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:57,751 - distributed.worker.memory - WARNING - Worker is at 89% memory usage. Pausing worker.  Process memory: 142.48 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:57,754 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.48 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:51:59,995 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.82 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:00,088 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.38 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:00,109 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.38 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:00,268 - distributed.worker.memory - WARNING - Worker is at 91% memory usage. Pausing worker.  Process memory: 146.29 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:00,269 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 146.29 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:00,316 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.92 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:00,361 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.47 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:00,583 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.11 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:00,654 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.50 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:00,765 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.13 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:00,772 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.48 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:00,776 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.87 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:00,780 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.48 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:00,792 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.97 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:00,831 - distributed.worker.memory - WARNING - Worker is at 89% memory usage. Pausing worker.  Process memory: 143.54 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:00,832 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 143.54 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:00,857 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 144.00 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:00,938 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.59 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,000 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.18 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,004 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 143.06 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,028 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 143.81 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,047 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.84 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,055 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.51 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,128 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.35 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,140 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.52 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,152 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.27 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,162 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.89 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,286 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.86 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,398 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.67 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,429 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.61 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,439 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 144.75 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,661 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.47 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,704 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.73 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,718 - distributed.worker.memory - WARNING - Worker is at 87% memory usage. Pausing worker.  Process memory: 140.23 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,719 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 143.68 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,719 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.23 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,746 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.58 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,754 - distributed.worker.memory - WARNING - Worker is at 90% memory usage. Pausing worker.  Process memory: 145.28 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,754 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 145.28 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,771 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.80 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,778 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.80 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,814 - distributed.worker.memory - WARNING - Worker is at 89% memory usage. Pausing worker.  Process memory: 143.15 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,814 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 143.15 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,834 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 144.33 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,835 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 139.72 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,843 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.28 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,916 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.94 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,947 - distributed.worker.memory - WARNING - Worker is at 87% memory usage. Pausing worker.  Process memory: 140.24 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:01,948 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.24 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:02,000 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 144.11 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:02,049 - distributed.worker.memory - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 141.98 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:02,050 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.98 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:02,097 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 144.01 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:02,102 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.55 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:02,192 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.74 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:02,210 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.98 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:02,259 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 143.68 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:02,288 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.00 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:02,296 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.89 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:02,306 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.04 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:02,311 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.08 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:02,361 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.16 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:02,393 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.45 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:02,419 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.50 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:02,465 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.54 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:02,639 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 139.44 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:02,949 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 139.95 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:03,422 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.04 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:04,100 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.91 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:06,297 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.90 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:06,559 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.31 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:07,129 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.18 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:07,135 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.72 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:07,784 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.74 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:09,995 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.84 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:10,136 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.64 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:10,332 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 144.55 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:10,371 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.49 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:10,422 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.93 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:10,586 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.12 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:10,758 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.52 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:10,766 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.15 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:10,876 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.89 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:10,878 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.75 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:10,879 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 143.73 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:10,912 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.98 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:10,940 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.61 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:10,958 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 144.02 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,000 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.20 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,102 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 143.07 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,129 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 143.83 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,146 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.86 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,150 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.52 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,155 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.29 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,161 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.53 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,231 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.36 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,244 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.90 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,287 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.87 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,443 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 144.76 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,448 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.69 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,539 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.62 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,720 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 143.69 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,737 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.49 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,756 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 143.49 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,766 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.41 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,802 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.75 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,804 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.05 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,846 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.60 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,881 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 143.46 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,926 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.30 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,930 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 139.74 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:11,932 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 144.35 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:12,015 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.95 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:12,028 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.45 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:12,068 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.20 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:12,106 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 144.11 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:12,112 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 144.02 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:12,113 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.57 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:12,192 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.75 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:12,289 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.02 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:12,297 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.90 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:12,306 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.06 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:12,310 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.00 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:12,361 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 143.69 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:12,411 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.10 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:12,439 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.52 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:12,456 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 140.17 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:12,496 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.47 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:12,564 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 142.55 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:12,641 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 139.45 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:12,951 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 139.97 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:13,459 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.06 MiB -- Worker memory limit: 160.00 MiB\n",
      "2025-02-27 12:52:14,204 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 141.92 MiB -- Worker memory limit: 160.00 MiB\n"
     ]
    }
   ],
   "source": [
    "## Local dask cluster \n",
    "client = Client(n_workers=64)\n",
    "\n",
    "#Cluster is starting! But can't get dashboard running\n",
    "\n",
    "#ood_dashboard_link = f\"https://hw-ood.cr.usgs.gov/node/{os.environ['JUPYTER_SERVER_NODE']}/{os.environ['JUPYTER_SERVER_PORT']}/proxy/{client.dashboard_link.split(':')[2]}\"\n",
    "#print(f\"Dask Dashboard is available at: {ood_dashboard_link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "285ac907-ed58-4e66-94e5-55307bfc8ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:25:37,283 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44042 remote=tcp://127.0.0.1:35967>: Stream is closed\n",
      "2025-02-27 10:25:37,286 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44070 remote=tcp://127.0.0.1:35967>: Stream is closed\n",
      "2025-02-27 10:25:37,287 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44068 remote=tcp://127.0.0.1:35967>: Stream is closed\n",
      "2025-02-27 10:25:37,287 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44074 remote=tcp://127.0.0.1:35967>: Stream is closed\n",
      "2025-02-27 10:25:37,290 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44026 remote=tcp://127.0.0.1:35967>: Stream is closed\n",
      "2025-02-27 10:25:37,291 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44056 remote=tcp://127.0.0.1:35967>: Stream is closed\n",
      "2025-02-27 10:25:37,290 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/lstaub/miniforge3/envs/wrfhydro_huc12_agg/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44060 remote=tcp://127.0.0.1:35967>: Stream is closed\n"
     ]
    }
   ],
   "source": [
    "client.shutdown()  # Gracefully shuts down the cluster\n",
    "client.close()     # Closes the client connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374124f5-d198-446f-84ee-aa955f931a22",
   "metadata": {},
   "source": [
    "#### Open the input file and read some useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f1086-a0cc-4f31-974e-80668a36cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def extract_dates(in_paths=[], format_str='%Y%m'):\n",
    "    '''\n",
    "    This function will take an input path and extract a date object from the filename. \n",
    "    Assumes that the filename ends with \"_{datestring}.nc\" (default = YYYYMM)\n",
    "    '''\n",
    "    dt_strings = [os.path.basename(in_path).split('.nc')[0].split('_')[1] for in_path in in_paths] \n",
    "    dt_obj = pd.to_datetime(dt_strings, format=format_str)\n",
    "    return dt_obj\n",
    "\n",
    "# Open the selected dataset(s), dropping variables as necessary\n",
    "drop_vars = [var_in for var_in in xr.open_dataset(file_in[0]).variables if var_in not in variables+[time_coord]]\n",
    "if len(file_in2)>1:\n",
    "    drop_vars += [var_in for var_in in xr.open_dataset(file_in2[0]).variables if var_in not in variables+[time_coord]]\n",
    "drop_vars = list(set(drop_vars)) # Eliminate redundancy\n",
    "print('Dropping {0} from input file.'.format(drop_vars))\n",
    "\n",
    "# Only use this method if datasets are coming from multiple directories or file types\n",
    "with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
    "    # This is a little complicated because we will be building multiple datasets\n",
    "    ds_list = [xr.open_mfdataset(in_list, \n",
    "                           combine='nested',\n",
    "                           decode_cf=False, \n",
    "                           concat_dim='time',\n",
    "                           chunks='auto', \n",
    "                           drop_variables=drop_vars) for in_list in [file_in, file_in2] if len(in_list)>0]\n",
    "    datetimes = [extract_dates(in_list) for in_list in [file_in, file_in2] if len(in_list)>0]\n",
    "    ds_list = [ds.assign_coords(time=datetimes_in) for ds, datetimes_in in zip(ds_list, datetimes)]\n",
    "    ds = xr.merge(ds_list)\n",
    "    del ds_list, datetimes\n",
    "    \n",
    "# Perform temporal subset, or not\n",
    "if temporal_subset:\n",
    "    ds = ds.loc[{time_coord:time_subset_bounds}]\n",
    "    \n",
    "# Obtain and print information about the input file\n",
    "ds, timesteps, x_chunk_sizes, y_chunk_sizes, time_chunk_sizes = report_structure(ds, variable=list(ds.data_vars.keys())[0])\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bd4ef5-3689-435c-8829-fcc3b26198e0",
   "metadata": {},
   "source": [
    "#### Obtain the spatial aggregation array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e8212-8b8a-4dc4-b2ac-6db2b146f435",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Choose a method for spatial aggregation\n",
    "raster_zones = True\n",
    "spatial_weights = False\n",
    "\n",
    "# Use a 2D grid of zone IDs to perform spatial aggregation.\n",
    "# This is a representation of the zones on the same grid as the analysis data.\n",
    "if raster_zones:\n",
    "    \n",
    "    # Sort out resolution and input files\n",
    "    if NWM_type == 'RTOUT':\n",
    "        zone_raster = r'/glade/scratch/ksampson/USGS/CONUS_Water_Budget/HUCs/HUC12s_on_250m_grid.tif'\n",
    "        LSM_grid = False\n",
    "    elif NWM_type == 'LDASOUT':\n",
    "        zone_raster = r'/glade/scratch/ksampson/USGS/CONUS_Water_Budget/HUCs/HUC12s_on_1000m_grid.tif'\n",
    "        LSM_grid = True\n",
    "    print('Using raster grid of zones for spatial aggregation: {0}'.format(zone_raster))\n",
    "    \n",
    "    # Data value to define nodata in the zone rater (anywhere that a zone does not exist).\n",
    "    zone_nodata = 0\n",
    "\n",
    "    # Read in the raster that defines the zones\n",
    "    zone_arr, zone_ndv = return_raster_array(zone_raster)\n",
    "\n",
    "    # Flip the raster if necessary - easier than flipping each input array from the model data\n",
    "    if LSM_grid:\n",
    "        zone_arr = zone_arr[flip_dim(['y', 'x'], DimToFlip='y')]\n",
    "\n",
    "    # Replace nodata values with np.nan, which requires converting to floating point.    \n",
    "    zone_arr = zone_arr.astype('float')    \n",
    "    zone_arr[zone_arr==zone_nodata] = np.nan\n",
    "\n",
    "    # Obtain unique values\n",
    "    zone_uniques = np.unique(zone_arr)\n",
    "    zones_unique = zone_uniques[zone_uniques!=np.nan]\n",
    "    print('{0} zones found in the input dataset'.format(zones_unique.shape[0]-1))\n",
    "    del zone_uniques, zones_unique\n",
    "    \n",
    "    # Add zones to the Xarray DataSet object\n",
    "    zones = xr.DataArray(zone_arr, dims=(\"y\", \"x\"), name=zone_name)\n",
    "    #ds[zone_name] = zones.fillna(-1).astype(int)   # workaround flox bug\n",
    "    ds[zone_name] = zones.fillna(-1).astype(np.int64)   # workaround flox bug\n",
    "    del zones\n",
    "    \n",
    "    # Obtain landmask grid\n",
    "    if landmask_results and NWM_type == 'LDASOUT':\n",
    "        print('  Masking zone grid to LSM LANDMASK variable')\n",
    "        landmask = xr.open_dataset(geogrid)['LANDMASK'].squeeze()\n",
    "        zone_masked = zone_arr.copy()\n",
    "        zone_masked[landmask==0] = np.nan\n",
    "        masked_zone_name = '{0}_masked'.format(zone_name)\n",
    "        zones_ma = xr.DataArray(zone_masked, dims=(\"y\", \"x\"), name=masked_zone_name)\n",
    "        \n",
    "        # Filling NaN areas (water or ocean) with -1 removes it from that HUC.\n",
    "        #ds[masked_zone_name] = zones_ma.fillna(-1).astype(int)   # workaround flox bug\n",
    "        ds[masked_zone_name] = zones_ma.fillna(-1).astype(np.int64)   # workaround flox bug\n",
    "        \n",
    "        # Save the landmask (1s and 0s)\n",
    "        landmask_da = xr.DataArray(landmask, dims=(\"y\", \"x\"), name='landmask')\n",
    "        ds['landmask'] = landmask_da.fillna(0).astype(int)   # workaround flox bug\n",
    "        del landmask, zones_ma\n",
    "    \n",
    "        # Obtain unique values\n",
    "        zone_uniques = np.unique(zone_masked)\n",
    "        zones_unique = zone_uniques[zone_uniques!=np.nan]\n",
    "        print('{0} zones found in the input dataset after land-masking'.format(zones_unique.shape[0]-1))\n",
    "        del zone_uniques, zones_unique, zone_masked\n",
    "        \n",
    "    del zone_arr\n",
    "    \n",
    "# Use a 1D array of pixel weights to perform spatial aggregation\n",
    "### NOT YET WORKING!\n",
    "elif spatial_weights:\n",
    "    sw_file = r'/glade/scratch/ksampson/USGS/CONUS_Water_Budget/Spatial_Weights/CONUS_HUC12_NWM1km_spatialweights.nc'\n",
    "    print('Using pre-computed NWM-style spatial weight file for spatial aggregation: {0}'.format(sw_file))\n",
    "    \n",
    "    # If the raster used to create spatial weights was created in GIS, then it will start with 0,0 in UL corner. \n",
    "    # To flip to south_north, select flip_raster==True\n",
    "    flip_raster = True\n",
    "    \n",
    "    # Open the spatial weight file\n",
    "    sw_ds = xr.open_dataset(sw_file)\n",
    "\n",
    "    # Subset the spatial weight file to just one zone\n",
    "    sw_ds = sw_ds.drop(['overlaps', 'polyid', 'regridweight'])\n",
    "    sw_ds.load()\n",
    "    \n",
    "    display(sw_ds)\n",
    "\n",
    "    # For now, flox need an integer for the zone IDs\n",
    "    sw_ds['IDmask'] = sw_ds['IDmask'].astype(np.int64)\n",
    "    sw_ds = sw_ds.rename({'IDmask':zone_name})\n",
    "\n",
    "    # Obtain indexer arrays and alter the indices to 'flip' the y dimension if requested.\n",
    "    indexer_i = sw_ds['i_index'].astype(int).data\n",
    "    if flip_raster:\n",
    "        indexer_j = LSM_grid_size_y - sw_ds['j_index'].astype(int).data\n",
    "    else:\n",
    "        indexer_j = sw_ds['j_index'].astype(int).data\n",
    "        \n",
    "    # Add the spatial weight variables to the dataset\n",
    "    ds = xr.merge([ds, sw_ds])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eee781-3e11-47fb-9a7c-d0930a566f4f",
   "metadata": {},
   "source": [
    "## Iterate over time, processing the zonal statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a35f66-ea7b-40f9-b73e-88751424865b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Perform 2D Groupby operation\n",
    "\n",
    "This codeblock will execute the 2D groupby (zonal statistic) operation using the `flox` method `xarray_reduce` or `groupby_reduce`.\n",
    "\n",
    "#### Method of operation\n",
    "\n",
    "For some datasets there may be a memory limitation that will cause individual workers to pause once they reach 80% memory utilization. Thus, we have to carefully select the size of chunks to process. Currently, we use the existing chunk size in the input Zarr store, establishing our iteration strategy on how many time-chunks from the input we can process at once. Keep in mind that the full 2D dataset will be used at each timestep, so only the time chunk will be considered. The `time_chunk_factor` is used to multiply the time-chunk to determine the number of timesteps processed at each iteration. Keep in mind that processing times appear to scale linearly, so this may not be an important factor.\n",
    "\n",
    "Currently, for certain variables, we calculate the sum over a third dimension, such as soil_layers_stag for the `SOIL_M` variable. \n",
    "\n",
    "Currently, the statistical operations provided in the `numpy_groupies` python library are supported:\n",
    "* `sum`, `nansum`\n",
    "* `prod`, `nanprod`\n",
    "* `mean`, `nanmean`\n",
    "* `var`, `nanvar`\n",
    "* `std`, `nanstd`\n",
    "* `min`, `nanmin`\n",
    "* `max`, `nanmax`\n",
    "* `first`, `nanfirst`\n",
    "* `last`, `nanlast`\n",
    "* `argmax`, `nanargmax`\n",
    "* `argmin`, `nanargmin`\n",
    "\n",
    "An output CSV is issued for each iteration and each statistic requested.\n",
    "\n",
    "Other configurations are set to assist in the chunking of the data. A variable `time_chunk_factor` is used to calculate how many timestep chunks to use for each iteration. One CSV file is written out per iteration, per statistic calculated (currently `mean` and `max` are supported)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c38a74c-c9eb-4f72-8abd-dfc0865aa44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print('Process initiated at {0}'.format(time.ctime()))\n",
    "        \n",
    "# Output to file\n",
    "with performance_report(filename=os.path.join(outDir, \"dask-report_2D_2.html\")):  \n",
    "    \n",
    "    # Determine how many time chunks we can process at once\n",
    "    time_chunks = [timesteps]    # To process all times at once, provide nested list containing all timesteps\n",
    "    print('There will be {0} iterations over time.'.format(len(time_chunks)))\n",
    "\n",
    "    # Iterate over variables\n",
    "    datetime_strings = []\n",
    "    print('There will be up to {0} variables processed.'.format(len(variables)))\n",
    "    for varnum, variable in enumerate(addVars+variables):\n",
    "        tic1 = time.time()\n",
    "        #if variable not in ds:\n",
    "        #    print('Skipping variable {0}'.format(variable))\n",
    "        #    continue\n",
    "        print('Processing variable {0}'.format(variable))\n",
    "\n",
    "        # Set the appropriate zone mask\n",
    "        if variable in non_landmask_vars+['Precip']:\n",
    "            # Use full basin zone array for spatial aggregation. No land-masking\n",
    "            print('  Using full basin mask for variable {0}'.format(variable))\n",
    "            zone_da = ds[zone_name]\n",
    "\n",
    "            # Special case where we re-use a variable to produce a secondary result\n",
    "            if variable == 'Precip':\n",
    "                da = ds['totPRECIP']\n",
    "                da.name = variable\n",
    "        else:\n",
    "            print('  Using land/water mask to remove water cells from analysis')\n",
    "            # Use land-masked zone array for spatial aggregation\n",
    "            zone_da = ds[masked_zone_name]\n",
    "\n",
    "        # Subset the variable to a DataArray\n",
    "        if variable in ds:\n",
    "            da = ds[variable]\n",
    "\n",
    "        # Special case to gather gridded area considered for each basin\n",
    "        elif variable == 'total_gridded_area':\n",
    "            # Make an array of ones to collect the total gridded area for each basin\n",
    "            da = xr.ones_like(ds['landmask'])\n",
    "            da.name = variable\n",
    "\n",
    "        # Initialize list to store temporary partial DataArrays\n",
    "        outputs = []\n",
    "\n",
    "        # Iterate over time-chunks and process zonal statistics\n",
    "        for n,time_chunk in enumerate(time_chunks):\n",
    "\n",
    "            # Interpret times as strings - for later input to CSV files as a time index\n",
    "            datetime_strings += [pd.to_datetime(time_chunk).strftime('%Y%m%d%H')]\n",
    "\n",
    "            # Subset in time if necessary\n",
    "            if 'time' in da.dims:\n",
    "                data = da.loc[dict(time=slice(time_chunk[0], time_chunk[-1]))]\n",
    "            else:\n",
    "                data = da\n",
    "\n",
    "            # Handle total soil moisture depth\n",
    "            if NWM_type == 'LDASOUT' and variable in ['SOIL_M','deltaSOILM','avgSOILM']:\n",
    "                print('\\tConverting soil mositure value to total water depth (mm) in soil column.')\n",
    "\n",
    "                # For Soil Moisture, apply weights to soil depths to get total volume (in mm) in soil column.\n",
    "                soil_dict = dict(soil_weights=(\"soil_layers_stag\", [0,1,2,3]))\n",
    "                weights = xr.DataArray(soil_depths_mm, dims=(\"soil_layers_stag\",), coords=soil_dict)\n",
    "\n",
    "                # Multiply by depth and sum the values over depth dimension\n",
    "                data = (data * weights).sum(dim='soil_layers_stag')\n",
    "                data.name = variable  # reset the dataarray name\n",
    "\n",
    "            # Apply groupby operation\n",
    "            if raster_zones:\n",
    "                if variable == 'total_gridded_area':\n",
    "                    flox_function = 'sum'\n",
    "                else:\n",
    "                    flox_function = 'mean'\n",
    "                print('\\t[{0}]    Calculating zonal {1}.'.format(varnum, flox_function))\n",
    "                output = run_flox(data, zone_da, flox_function=flox_function, n=n)\n",
    "            elif spatial_weights:\n",
    "                # Convert from 2D to 1D array using indexer_j and indexer_i\n",
    "                flox_function = 'sum'\n",
    "                print('\\t[{0}]    Calculating spatially weighted value.'.format(varnum, flox_function))\n",
    "                output = run_flox(data.data[indexer_j, indexer_i] * ds['weight'], \n",
    "                                  zone_da, \n",
    "                                  flox_function=flox_function, \n",
    "                                  n=n)\n",
    "            if variable not in non_landmask_vars+['Precip']:\n",
    "                output = output.rename({masked_zone_name:zone_name})\n",
    "            outputs.append(output)\n",
    "            del data\n",
    "        print('\\t[{0}] Spatial aggregation step completed in {0:3.2f} seconds.'.format(varnum, time.time()-tic1))\n",
    "\n",
    "        # Merge all outputs together\n",
    "        output = xr.merge(outputs)\n",
    "\n",
    "        # Re-arrange dimensions so that time is the fastest varying dimension\n",
    "        if 'time' in output.dims:\n",
    "            output = output[[zone_name, time_coord, variable]]\n",
    "\n",
    "        #if varnum == 0:\n",
    "        if not 'out_ds' in locals():\n",
    "            out_ds = output\n",
    "        else:\n",
    "            out_ds[variable] = output[variable]\n",
    "        print('\\t[{0}] Iteration completed in {1:3.2f} seconds.'.format(varnum, time.time()-tic1))\n",
    "    out_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8096f811-4cfb-4907-bbe1-19c733998485",
   "metadata": {},
   "source": [
    "### Remove unecessary attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121b2ec1-69bd-4587-b841-385f3f3a0848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate any unecessary variable attributes (such as spatial metadata)\n",
    "for variable in out_ds.data_vars:\n",
    "    if 'grid_mapping' in out_ds[variable].attrs:\n",
    "        del out_ds[variable].attrs['grid_mapping']\n",
    "    if 'esri_pe_string' in out_ds[variable].attrs:\n",
    "        del out_ds[variable].attrs['esri_pe_string']\n",
    "    if 'proj4' in out_ds[variable].attrs:\n",
    "        del out_ds[variable].attrs['proj4']\n",
    "    if variable == 'landmask':\n",
    "        out_ds[variable].attrs = {'description':'Fraction of gridded land area in each HUC12'}\n",
    "    if variable == 'total_gridded_area':\n",
    "        out_ds[variable].attrs = {'description':'Number of 1km grid cells for HUC12. Equivalend to square kilometers. Based on grid association of each HUC12'}\n",
    "        \n",
    "# Now eliminate unnecessary global attributes\n",
    "if 'grid_mapping' in out_ds.attrs:\n",
    "    del out_ds.attrs['grid_mapping']\n",
    "if 'units' in out_ds.attrs:\n",
    "    del out_ds.attrs['units']  \n",
    "if 'esri_pe_string' in out_ds.attrs:\n",
    "    del out_ds.attrs['esri_pe_string'] \n",
    "if 'long_name' in out_ds.attrs:\n",
    "    del out_ds.attrs['long_name'] \n",
    "if '_FillValue' in out_ds.attrs:\n",
    "    del out_ds.attrs['_FillValue'] \n",
    "if 'missing_value' in out_ds.attrs:\n",
    "    del out_ds.attrs['missing_value'] \n",
    "out_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e90014-2b0b-4a33-ad9f-e0739ed65633",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ds = out_ds.where(out_ds[zone_name]!=-1, drop=True)\n",
    "out_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87005406-8e5e-4df0-af1f-a5995ca2c1d6",
   "metadata": {},
   "source": [
    "### Output to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e512ce9-3b22-4af2-bd39-0d17f23af49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Read into memory before writing to disk?\n",
    "out_ds.compute()\n",
    "\n",
    "# Write output file (CSV)\n",
    "if write_CSV:\n",
    "    tic1 = time.time()\n",
    "    out_file = os.path.join(outDir, output_pattern+'_2.csv')\n",
    "    print('  Writing output to {0}'.format(out_file))\n",
    "    if os.path.exists(out_file):\n",
    "        tic1 = time.time()\n",
    "        df_in = pd.read_csv(out_file)\n",
    "        df_out = pd.concat([df_in, out_ds.to_dataframe()])\n",
    "        df_out.to_csv(out_file)\n",
    "        print('\\t      Output file written in {0:3.2f} seconds.'.format(time.time()-tic1))\n",
    "    else:\n",
    "        write_csv(out_ds, out_file, columns=output[zone_name], index=[datetime_strings])\n",
    "    print('\\tExport to CSV completed in {0:3.2f} seconds.'.format(time.time()-tic1))\n",
    "    \n",
    "# Write output file (netCDF)\n",
    "if write_NC:\n",
    "    tic1 = time.time()\n",
    "    out_file = os.path.join(outDir, output_pattern+'_2.nc')\n",
    "    if os.path.exists(out_file):\n",
    "        in_ds = xr.open_dataset(out_file).load()\n",
    "        out_ds2 = xr.merge([in_ds, out_ds.transpose()])\n",
    "        in_ds.close()\n",
    "        del in_ds\n",
    "        print('  Writing output to {0}'.format(out_file))\n",
    "        out_ds2.to_netcdf(out_file, mode='w', format=\"NETCDF4\", compute=True)\n",
    "        del out_ds2\n",
    "    else:\n",
    "        print('  Writing output to {0}'.format(out_file))\n",
    "        out_ds.transpose().to_netcdf(out_file, mode='w', format=\"NETCDF4\", compute=True)\n",
    "    print('\\tExport to netCDF completed in {0:3.2f} seconds.'.format(time.time()-tic1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afe894c-fbab-4fe4-b5ce-0a3d8a3ab8db",
   "metadata": {},
   "source": [
    "## Spin Down the Cluster and Close datasets\n",
    "##### After we are done, we can spin down our cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874cac1f-69d1-40f4-9d37-df8765322f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the Dask cluster\n",
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c347a11-194d-40a5-98ab-dbca1088e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close dataset\n",
    "ds.close()\n",
    "print('Process completed in {0: 3.2f} seconds.'.format(time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccbb614-f86b-4525-8f75-a98f063ccedc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6245a97-8971-48af-b5f8-00da9c345caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dde333-a186-452c-8e5b-9362372538b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5c6b017-d49a-4754-ae84-834409a41f51",
   "metadata": {},
   "source": [
    "### The following is an attempt to compute a spatially weighted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fedadaa-cb9c-4da8-8fdd-fff58e319113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# import dask.array as da\n",
    "\n",
    "# varnum = 0\n",
    "# variable = 'deltaACCET'\n",
    "# unit = 'mm'\n",
    "\n",
    "# print('Process initiated at {0}'.format(time.ctime()))\n",
    "\n",
    "# print('Processing variable {0}'.format(variable))\n",
    "# da_in = ds[variable]\n",
    "\n",
    "# # Setup vindex on dask array to re-shape the data\n",
    "# #if spatial_weights:\n",
    "# da_out = da_in.isel({'time': [0,1]})\n",
    "# da_out = da_in.data.vindex[:, indexer_j, indexer_i].compute()\n",
    "# da_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8d8721-a401-4055-bbac-2535d2d03a7d",
   "metadata": {},
   "source": [
    "#### Pre-processing step, if the input is raw NWM and has not already been pre-processed (subset, de-accumulate, time aggregation, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512a3fc8-64a6-4b56-8bf5-ca2cdd7649c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# print('Process initiated at {0}'.format(time.ctime()))\n",
    "      \n",
    "\n",
    "# Resample the time variable to daily if t_resample is True - only relevant if t_resample == True\n",
    "# Also used in the output variable name, so choose something that indicates the temporal resolution\n",
    "# #resample_time_period = \"1D\"\n",
    "# resample_time_period = '1M'\n",
    "\n",
    "# # Remove accumulated signal from accumulated variables?\n",
    "# de_accumulate = False\n",
    "\n",
    "# # List the accumulated variables in this dataset. Only necessary when de_accumulate==True\n",
    "# accum_vars = ['ACCET', 'UGDRNOFF']  \n",
    "# accum_var_renamed = {'ACCET':'ET'}\n",
    "\n",
    "# # Determine how many time chunks we can process at once\n",
    "# time_chunk_factor = 1\n",
    "# time_chunks = split_given_size(timesteps, int(time_chunk_sizes[0]*time_chunk_factor))\n",
    "# time_chunks = [time_chunks[0]]\n",
    "\n",
    "# # To process all times at once\n",
    "# #time_chunks = [timesteps]    \n",
    "\n",
    "# # Iterate over time-chunks and process zonal statistics\n",
    "# print('There will be {0} iterations.'.format(len(time_chunks)))\n",
    "# for n,time_chunk in enumerate(time_chunks):\n",
    "#     tic1 = time.time()\n",
    "    \n",
    "#     # Interpret times as strings\n",
    "#     datetime_strings = pd.to_datetime(time_chunk).strftime('%Y%m%d%H')\n",
    "\n",
    "#     # Subset in time if necessary\n",
    "#     #data = ds[variable].loc[dict(time=slice(time_chunk[0], time_chunk[-1]))]\n",
    "#     data = ds.loc[dict(time=slice(time_chunk[0], time_chunk[-1]))]\n",
    "\n",
    "#     # For accumulated variables, we will attempt to difference over time then aggregagte\n",
    "#     if variable in accum_vars:\n",
    "\n",
    "#         if de_accumulate:\n",
    "#             stat = 'sum'\n",
    "#             print('De-accumulating the {0} variable.'.format(variable))\n",
    "#             rename_var = accum_var_renamed.get(variable, variable)\n",
    "#             if rename_var != variable:\n",
    "#                 print('Renaming variable from {0} to {1}.'.format(variable, rename_var))\n",
    "#                 data = data.rename({variable:rename_var})\n",
    "#                 variable = rename_var\n",
    "#             max_factor = 1.2            \n",
    "#             de_accumulated = data[variable].diff(dim='time').rename(rename_var)\n",
    "\n",
    "#             # Build a mask, wherever the difference is greater than the max difference for each cell time-series\n",
    "#             print('Calculating max difference for each cell.')\n",
    "#             mask_val = -de_accumulated.max(dim='time') * max_factor\n",
    "#             mask_val.load()\n",
    "#             restart_mask = de_accumulated >= mask_val\n",
    "\n",
    "#             # The block below helps diagnose if the criteria is sufficient to determine the model restart times\n",
    "#             #restart_locations = de_accumulated.where(de_accumulated < mask_val, drop=True)\n",
    "#             #print('Found {0} timesteps where a restart may have occured based on the criteria'.format(restart_locations.shape[0]))\n",
    "\n",
    "#             # Alter values after each restart location to the non differenced values from the original accumulated array\n",
    "#             if t_resample:\n",
    "#                 da = (de_accumulated.where(\n",
    "#                     de_accumulated >= mask_val, \n",
    "#                     other = data[variable].isel(time=slice(1,None,None)),\n",
    "#                     drop = False)\n",
    "#                     .resample(time=resample_time_period)\n",
    "#                     .sum(dim='time'))  \n",
    "#             else:\n",
    "#                 da = (de_accumulated.where(\n",
    "#                     de_accumulated >= mask_val, \n",
    "#                     other = data[variable].isel(time=slice(1,None,None)),\n",
    "#                     drop = False)\n",
    "#         else:\n",
    "#             # For accumulated variables, we want the LAST value of each time aggregation\n",
    "#             stat = 'last'\n",
    "#             print('Writing LAST value of each day to output.')\n",
    "#             if t_resample:\n",
    "#                 da = (\n",
    "#                     data[variable]\n",
    "#                     .resample(time=resample_time_period, closed='right')\n",
    "#                     .last(skipna=False))  # significant user decision\n",
    "#             else:\n",
    "#                 da = data[variable]\n",
    "                \n",
    "#     # Handle percent saturation if requested\n",
    "#     elif pct_sat and NWM_type == 'LDASOUT' and variable in ['SOIL_M',]:\n",
    "#         print('Converting soil mositure value to soil saturation percent.')\n",
    "#         data = soil_water_pct_sat(data)\n",
    "#         variable = 'soil_water_pct_sat'\n",
    "\n",
    "#         # For Soil Moisture, apply weights to soil depths to get total volume (in mm) in soil column.\n",
    "#         stat = 'mean'\n",
    "#         print('Converting to mm and summing over soil_layers_stag')\n",
    "#         soil_dict = dict(soil_weights=(\"soil_layers_stag\", [0,1,2,3]))\n",
    "#         weights = xr.DataArray(soil_depths_mm, dims=(\"soil_layers_stag\",), coords=soil_dict)\n",
    "#         data[variable] = data[variable] * weights\n",
    "\n",
    "#         # Sum the variables over depth dimension\n",
    "#         if t_resample:\n",
    "#             da = data[variable].sum(dim='soil_layers_stag').resample(time=resample_time_period).mean(dim='time') \n",
    "#         else:\n",
    "#             da = data[variable].sum(dim='soil_layers_stag')\n",
    "\n",
    "#     # For all other variables, calculate the mean of the variable over the aggregated timestep\n",
    "#     else:\n",
    "#         if t_resample:\n",
    "#             stat = 'mean'\n",
    "#             print('Writing MEAN across each {0} to output'.format(resample_time_period))\n",
    "#             da = (\n",
    "#                 data[variable]\n",
    "#                 .resample(time=resample_time_period)\n",
    "#                 .mean(dim='time'))\n",
    "#         else:\n",
    "#             da = data[variable]\n",
    "            \n",
    "#     # Apply groupby operation  \n",
    "#     flox_function = 'mean'\n",
    "#     print('\\t[{0}]    Calculating zonal {1}.'.format(n, flox_function))\n",
    "#     output = run_flox(data, data[zone_name], flox_function=flox_function, n=n)\n",
    "\n",
    "#     # convert from rate (m^3/s) to depth (m) over a day (86400s) or hour (3600s)\n",
    "#     if convert_to_mm and variable in ['RAINRATE'] and flox_function=='mean':\n",
    "#         print('Converting from a rate (mm/s) to sum across each {0} to output'.format(resample_time_period))\n",
    "#         if t_resample:\n",
    "#             time_duration = pd.Timedelta(resample_time_period)\n",
    "#             seconds = time_duration.total_seconds()\n",
    "#         else:\n",
    "#             seconds = input_timestep_seconds\n",
    "#         print('Multiplying rate from mm/s to mm over timestep ({0} seconds.)'.format(seconds))\n",
    "#         output = (output*seconds)\n",
    "    \n",
    "#     # Write output file (CSV)\n",
    "#     if write_CSV:\n",
    "#         out_file = os.path.join(outDir, '{0}_{1}_{2}_{3}.csv'.format(region, variable, flox_function, n))\n",
    "#         write_csv(output.data, out_file, columns=output[zone_name], index=[datetime_strings], drops=[-1])\n",
    "#         del output, out_file, flox_function            \n",
    "\n",
    "#     # Write output file (netCDF)\n",
    "#     if write_NC:\n",
    "#         # Add geospatial data to output from the GEOGRID LDASOUT Spatial Metadata file\n",
    "#         # output = output.to_dataset(name=variable)\n",
    "#         if add_SM:\n",
    "#             output = add_SM_to_ds(output, variable, ds_geo=geo_input, grid_type=NWM_type)\n",
    "        \n",
    "#         out_file = os.path.join(outDir, nc_output_pattern.format(filetype=NWM_type, variable=variable, region=region, unit=units, time=resample_time_period, stat=flox_function))\n",
    "#         print('  Writing output to {0}'.format(out_file))\n",
    "#         output.to_netcdf(out_file, mode='w', format=\"NETCDF4\", compute=True)\n",
    "        \n",
    "#     del data, datetime_strings\n",
    "#     print('\\t[{0}] Iteration completed in {1:3.2f} seconds.'.format(n, time.time()-tic1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
